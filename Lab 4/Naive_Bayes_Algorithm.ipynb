{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import csv\n", 
        "import random"
      ],
      "metadata": {
        "id": "3edtj77vOjf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This make sures that the dataset is in an ordered format. If we have some arbirary names in that column it difficult to deal with that.\n",
        "\n",
        "def encode_class(dataset):\n",
        "  classes=[]\n",
        "  for i in range(len(dataset)):\n",
        "    if dataset[i][-1] not in classes:\n",
        "      classes.append(dataset[i][-1])\n",
        "  \n",
        "  # Looping across the classes which we have derived above.This will make sure that we have definitive classes (numeric) and not arbitrary\n",
        "  for i in range(len(classes)):\n",
        "    # Looping across all rows of dataset\n",
        "    for j in range(len(dataset)):\n",
        "      if dataset[j][-1] == classes[i]:\n",
        "        dataset[j][-1]=i\n",
        "  return dataset "
      ],
      "metadata": {
        "id": "Gy5i2q7xOtrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data between training set and testing set. Normally its a general understanding the training:testing=7:3\n",
        "\n",
        "def train_test_split(dataset,ratio):\n",
        "  test_num=int(ratio*len(dataset))\n",
        "  train=list(dataset)\n",
        "  test=[]\n",
        "  for i in range(test_num):\n",
        "    rand=random.randrange(len(train))\n",
        "    test.append(train.pop(rand))\n",
        "  return train,test"
      ],
      "metadata": {
        "id": "hr3cxgabSO_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now depending on resultant value (last column values), we need to group the rows. It will be usefult for calculating mean and std_dev\n",
        "\n",
        "def groupUnderClass(train):\n",
        "  dict={}\n",
        "  for row in train:\n",
        "    if row[-1] not in dict:\n",
        "      dict[row[-1]]=[]\n",
        "    dict[row[-1]].append(row)\n",
        "  return dict"
      ],
      "metadata": {
        "id": "e19OvPiSVSt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard formulae (just by-heart)\n",
        "\n",
        "def mean(val):\n",
        "  return sum(val)/float(len(val)) #Obvious\n",
        "\n",
        "def stdDev(val):\n",
        "  avg=mean(val)\n",
        "  variance=sum([pow(x-avg,2) for x in val])/float(len(val)-1) # Especially this one\n",
        "  return math.sqrt(variance)"
      ],
      "metadata": {
        "id": "7P77xKdRXD37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will calculte the mean and std dev with respect to each attribute. Important while calculating gaussian probablity\n",
        "\n",
        "def meanStdDev(instances):\n",
        "  info=[(mean(x),stdDev(x)) for x in zip(*instances)] # Here we are taking complete column's values of all instances.\n",
        "  del info[-1]\n",
        "  return info"
      ],
      "metadata": {
        "id": "Mtc9UVx0Wnj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As explained earlier why e need to group. We will be calculating the mean and std dev with respect each class.\n",
        "\n",
        "def MeanAndStdDevForClass(train):\n",
        "  info={}\n",
        "  dictionary=groupUnderClass(train)\n",
        "  # print(dictionary)\n",
        "  for key,value in dictionary.items():\n",
        "    # dictionary[key]=meanStdDev(value)\n",
        "    info[key]=meanStdDev(value) #Here value stands for a complete group.\n",
        "  return info"
      ],
      "metadata": {
        "id": "c490foOUUq_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Its a formula by heart (no choice)\n",
        "\n",
        "def calculateGaussianProbablity(x,mean,std_dev):\n",
        "  expo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(std_dev, 2))))\n",
        "  return (1 / (math.sqrt(2 * math.pi) * std_dev)) * expo"
      ],
      "metadata": {
        "id": "j9vK7AzadGM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After calculating mean and std dev w.r.t training data now its time to check if the logic will work on testing data\n",
        "\n",
        "\n",
        "def calculateClassProbablities(info,ele):\n",
        "  probablities={}\n",
        "  for key,summaries in info.items(): # Info contains the groupName (key) and list of (mean,std_dev) for each attribute of that group\n",
        "    probablities[key]=1\n",
        "    for i in range(len(summaries)): #Loop across all attributes \n",
        "      mean,std_dev=summaries[i]\n",
        "      x=ele[i] # Testing data's one instance's attribute value.\n",
        "      probablities[key] *= calculateGaussianProbablity(x, mean, std_dev)\n",
        "  return probablities"
      ],
      "metadata": {
        "id": "FYwqdaCdcNHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(info,ele):\n",
        "  probablities=calculateClassProbablities(info,ele) # returns a dictionary of probablities for each group\n",
        "  bestLabel,bestProb=None,-1\n",
        "  # Consider group name whichever gives you the highest probablities for this instance of testing data \n",
        "  for key,prob in probablities.items():\n",
        "    if bestLabel==None or prob>bestProb:\n",
        "      bestProb=prob\n",
        "      bestLabel=key\n",
        "  return bestLabel"
      ],
      "metadata": {
        "id": "bx60fKeKZskm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop across testing data and store the predicted result from our model in the list.\n",
        "\n",
        "def getPredictions(info,test):\n",
        "  predictions=[]\n",
        "  for ele in test:\n",
        "    result=predict(info,ele) # This will give you the group to which it will belong.\n",
        "    predictions.append(result)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "MQveyyyKY_3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(predictions,test):\n",
        "  count=0\n",
        "  for i in range(len(test)):\n",
        "    if predictions[i]==test[i][-1]:\n",
        "      count+=1\n",
        "  return count/float(len(test))*100"
      ],
      "metadata": {
        "id": "-1Z84srVe_ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"/content/bayes.csv\"\n",
        "dataset=csv.reader(open(filename))\n",
        "dataset=list(dataset)\n",
        "dataset=encode_class(dataset)\n",
        "for i in range(len(dataset)):\n",
        "  dataset[i]=[float(x) for x in dataset[i]]\n",
        "\n",
        "ratio=0.3\n",
        "print(len(dataset))\n",
        "train,test=train_test_split(dataset,ratio)\n",
        "info=MeanAndStdDevForClass(train)\n",
        "\n",
        "predictions=getPredictions(info,test)\n",
        "accuracy=check_accuracy(predictions,test)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "oDCV1blDQAa5",
        "outputId": "a965dbe9-b8fc-4144-9653-4c1869350bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.91954022988506"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Naive Bayes Algorithm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
